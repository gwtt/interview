1. 自我介绍

2. 项目拷打

3. 实习经历拷打

4. 对于项目的收获

5. 对于分布式id的理解，什么适用场景，能用什么方案，方案选型的权衡

   > 分布式ID就是分布式系统下的ID,最简单的例子就是两个服务器上的数据库，我要保证存放的东西主键唯一，为了不保证冲突，要使用分布式ID
   >
   > 场景适用在:
   >
   > 1. **订单编号**：电商平台需要为每个订单生成唯一的订单号。
   > 2. **支付流水号**：金融系统中，每一笔支付都需要一个唯一的标识。
   > 3. **用户ID**：社交网络和用户管理系统需要为每个用户分配一个唯一的ID。
   >
   > 方案可以选择
   >
   > 1.UUID，适用于不需要考虑ID自增的情形
   >
   > 2.数据库自增ID,适用于单数据库
   >
   > 3.Redis自增ID，缺点是依赖于Redis，要保证Redis稳定性
   >
   > 4.雪花算法生成ID，利用机器码和时间戳生成

6. redis保证分布式操作原子性的原理

   > 主要是redis每个命令是单线程的方式执行的，大部分命令都是原子操作，要么执行，要么不执行，这就保证了在分布式环境下也能保证操作原子性。然后也有事务机制和Lua脚本可以保证原子性。

7. 对于分库分表的理解，什么场景，具体怎么实现，选型的权衡，重点在于水平和垂直的区别

   > 分库：将原来存放在单个数据库中的数据，拆分到多个数据库中存放。
   >
   > 分表：将原来存放在单个表中的数据，拆分到多个表中存放。
   >
   > 场景：数据量越来越大，数据中数量太多导致访问性能变慢，就可以分库分表
   >
   > 四种方式：
   >
   > 垂直分库、水平分库、垂直分表、水平分表
   >
   > 垂直分表:就是将一个复杂的商品信息分开放在两个表里，比如商品表可以分为商品信息表和商品描述表，可以
   >
   > 水平分表:就是将一个表的数据分在两个表里面，主要解决单表数据量过大的问题
   >
   > 垂直分库:则是将一个数据库的东西分成两个数据库，专库专用，可以提升IO，分摊服务器压力
   >
   > 水平分库:跟水平分表差不多，数据分摊在两个数据库，不是专库专用，主要解决单库数据量大，高并发大的情形

8. 为什么分表后查询效率提高了，要求逻辑闭环的解释

   > 分表之后，数据量减少，在进行搜索时只需要搜索一个较小数据集。并且在大数据集中，索引变得特别庞大，导致索引查找效率低下。对于垂直分表，可以为常用字段创建更精细的索引，进一步提高查询效率。同时，分表后，不同的表可以分布在不同的数据库实例或服务器上，这允许多个查询并行执行，减少了锁的竞争和等待时间。在水平分表的情况下，查询可以并行地在不同的分片上执行，然后将结果汇总。

9. 主从分库一般怎么做数据同步

   > - 主要是利用binlog文件，主数据库上的更改都会同步到binlog中
   >
   > - 从数据库的I/O线程定期检查主数据库的二进制日志，并请求新的更改。
   > - 主数据库的二进制日志事件被发送到从数据库。
   > - 从数据库的SQL线程接收这些事件，并在本地重放，以确保数据与主数据库保持一致。

10. 主从分库里面会有一致性问题吗，分析分析这个场景满足CAP中的什么，要求举例子逻辑闭环的解释

    > 当然会有，Mysql默认异步复制，保证了AP

11. 为什么influxdb适用于时序数据场景

    > **传统的RDBMS数据库**对写入的支持都是按行处理，并建立B树结构的索引，它并不是为了批量高速写入而设计，尤其像多纬度时序数据连续的涌入数据平台，RDBMS的存储引擎必然导致负载、吞吐在写入性能上的极不适应。
    >
    > 因此时序数据的存储设计一般不会考虑传统RDBMS，都会将目光放在以LSM-Tree以及列式的数据结构存储方向。
    >
    > InfluxDB使用了LSM-Tree的数据结构。在这种数据结构下，磁盘是顺序写的，当操作到达一定数量，就会合并，再批量写入磁盘中，合并时，会和以前的数据做合并。所以说写很快，适合做时序数据库。
    > 

12. 了不了解XXXDB等newSQL，那些底层结构是怎么样的

    > 不了解

13. 来分析分析B+树和LSM树在时序数据处理上的性能差异，要求逻辑闭环的解释，对于时序数据处理上一般会有什么操作，这些操作在B+树发生的过程，在LSM树上又发生什么过程，然后这些过程产生了什么性能差异

    > ### B+树在时序数据处理上的操作和性能：
    >
    > 1. **写入操作**：
    >    - 在B+树中，写入操作涉及查找合适的叶子节点，然后将数据插入到树中。如果节点分裂，还需要更新父节点的指针。
    >    - 对于时序数据，由于数据通常是连续写入的，B+树可能需要频繁地进行节点分裂和树结构调整，这会导致写入性能下降。
    > 2. **查询操作**：
    >    - B+树的查询操作通常涉及从根节点到叶子节点的路径搜索，时间复杂度为O(log n)。
    >    - 对于时序数据的查询，通常需要根据时间戳进行范围查询，B+树可以有效地支持这种查询，但由于时序数据的写入模式，树的高度可能会增加，从而影响查询性能。
    > 3. **性能差异**：
    >    - B+树在写入时可能会遇到写放大问题，因为每次写入都可能需要更新多个节点。
    >    - 对于时序数据，B+树可能需要频繁的树结构调整，这会增加写入和查询的开销。
    >
    > ### LSM树在时序数据处理上的操作和性能：
    >
    > 1. **写入操作**：
    >    - LSM树通过将写入操作先追加到内存中的日志文件（Memtable），随后这些在memtable中的数据会被批量的合并到磁盘中的SSTable当中，**将随机写变为了顺序写**。
    >    - 对于时序数据，LSM树的写入操作是顺序的，这减少了磁盘寻道时间，提高了写入效率。
    > 2. **查询操作**：
    >    - LSM树的查询操作首先在Memtable中查找，然后逐层向下在SSTable中查找，直到找到数据或确定数据不存在。
    >    - 对于时序数据，LSM树的查询性能可能会受到SSTable合并（compaction）过程的影响，尤其是在数据量大时，合并操作可能会成为性能瓶颈。
    > 3. **性能差异**：
    >    - LSM树在写入时具有很高的性能，因为它避免了写放大，并且写入操作是顺序的。
    >    - 查询操作相较于B+树就会很慢了，读操作需要依次读取memtable、immutable memtable、SSTable0、SSTable1…。需要反序地遍历所有的集合，又因为写入顺序和合并顺序的缘故，序号小的集合中的数据一定会比序号大的集合中的数据新。所以在这个反序遍历的过程中一旦匹配到了要读取的数据，那么一定是最新的数据，只要返回该数据即可。但是如果一个数据不在所有的数据集合中，则会白白遍历一遍。

14. 螺旋矩阵

> ```java
> class Solution {
>     public List<Integer> spiralOrder(int[][] matrix) {
>         List<Integer> order = new ArrayList<Integer>();
>         if (matrix == null || matrix.length == 0 || matrix[0].length == 0) {
>             return order;
>         }
>         int rows = matrix.length, columns = matrix[0].length;
>         boolean[][] visited = new boolean[rows][columns];
>         int total = rows * columns;
>         int row = 0, column = 0;
>         int[][] directions = {{0, 1}, {1, 0}, {0, -1}, {-1, 0}};
>         int directionIndex = 0;
>         for (int i = 0; i < total; i++) {
>             order.add(matrix[row][column]);
>             visited[row][column] = true;
> 
>             int nextRow = row + directions[directionIndex][0], nextColumn = column + directions[directionIndex][1];
>             if (nextRow < 0 || nextRow >= rows || nextColumn < 0 || nextColumn >= columns || visited[nextRow][nextColumn]) {
>                 directionIndex = (directionIndex + 1) % 4;
>             }
>             
>             row += directions[directionIndex][0];
>             column += directions[directionIndex][1];
>         }
>         return order;
>     }
> }
> ```
>
> 